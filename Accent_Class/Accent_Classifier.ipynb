{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTACTION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_data\n",
    "  \n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Sounds\"\n",
    "JSON_PATH = \"data_10.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 1 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Sounds\\ME\n",
      "Sounds\\ME\\a-bush-in-kazakhstan-will-laugh-when-we-hear-the-name-becaus-it-bush-em-in-the-hair-around-the-testes-satchel.wav,\n",
      "Sounds\\ME\\a-little-better-tell-me-if-you-like-to-make-a-sex-crime-high-five.wav,\n",
      "Sounds\\ME\\a-little.wav,\n",
      "Sounds\\ME\\a-very-nice-he-have-a-like-a-tool-shaved-horses-bladder-over-river.wav,\n",
      "Sounds\\ME\\a-very-nice.wav,\n",
      "Sounds\\ME\\all-day-long-when-i-see-you-i-think-of-you-know-clothes-wow-we-were-but-is-a-very-wonderful.wav,\n",
      "Sounds\\ME\\and-best-thing-of-all.wav,\n",
      "Sounds\\ME\\and-he-is-a-strong-man-he-will-crush-his-opponents.wav,\n",
      "Sounds\\ME\\and-he-will-be-powerful-alike-styling-and-not-to-tolerate-people-who-are-bad.wav,\n",
      "Sounds\\ME\\and-here-will-be-powerful-and-like-a-styling-and-the-note-to-tolerate-people-who-are-bad.wav,\n",
      "\n",
      "Processing: Sounds\\UK\n",
      "Sounds\\UK\\after-three-years-of-unfounded-self-doubt-it-is-time-to-change-the-record.wav,\n",
      "Sounds\\UK\\against-the-pluck-a-nerve-and-ambition-of-this-country.wav,\n",
      "Sounds\\UK\\all-this-and-more-we-can-do-now-and-only-now-at-this-extraordinary.wav,\n",
      "Sounds\\UK\\always-observed-a-top-speed-limit-in-the.wav,\n",
      "Sounds\\UK\\and-and-and-and-and.wav,\n",
      "Sounds\\UK\\and-around-the-eu-i-am-convinced-we-can-do-a-deal.wav,\n",
      "Sounds\\UK\\and-as-affectionate-as-possible-and-the-first-step-is.wav,\n",
      "Sounds\\UK\\and-even-loved-around-the-world-for-our-inventiveness-farrar-hume.wav,\n",
      "Sounds\\UK\\and-fantastic-new-road-and-rail-infrastructure-and-full-fibre-broadband.wav,\n",
      "Sounds\\UK\\and-farming-sector-will-be-ready-and-waiting-to-continue-selling.wav,\n",
      "\n",
      "Processing: Sounds\\US\n",
      "Sounds\\US\\a-woman-that-looks-like-that-has-to-have-special-scent.wav,\n",
      "Sounds\\US\\ah-im-smart.wav,\n",
      "Sounds\\US\\ah-no.wav,\n",
      "Sounds\\US\\america-great-again.wav,\n",
      "Sounds\\US\\america.wav,\n",
      "Sounds\\US\\and-i-made-a-lot-of-money-in-atlantic-city-and-im-very-proud-of-it.wav,\n",
      "Sounds\\US\\and-i-will-tell-you-this-and-i-said-it-very-strongly.wav,\n",
      "Sounds\\US\\and-it-only-makes-common-sense.wav,\n",
      "Sounds\\US\\and-now-theyre-beating-us-economically-they-are-not-our-friend-believe-maine.wav,\n",
      "Sounds\\US\\and-some-i-assume-are-good-people.wav,\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(DATASET_PATH)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not DATASET_PATH:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                print(\"{},\".format(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "\t\t# load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Sounds\\ME\n",
      "Sounds\\ME\\a-bush-in-kazakhstan-will-laugh-when-we-hear-the-name-becaus-it-bush-em-in-the-hair-around-the-testes-satchel.wav, segment:1\n",
      "Sounds\\ME\\a-little-better-tell-me-if-you-like-to-make-a-sex-crime-high-five.wav, segment:1\n",
      "Sounds\\ME\\a-little.wav, segment:1\n",
      "Sounds\\ME\\a-very-nice-he-have-a-like-a-tool-shaved-horses-bladder-over-river.wav, segment:1\n",
      "Sounds\\ME\\a-very-nice.wav, segment:1\n",
      "Sounds\\ME\\all-day-long-when-i-see-you-i-think-of-you-know-clothes-wow-we-were-but-is-a-very-wonderful.wav, segment:1\n",
      "Sounds\\ME\\and-best-thing-of-all.wav, segment:1\n",
      "Sounds\\ME\\and-he-is-a-strong-man-he-will-crush-his-opponents.wav, segment:1\n",
      "Sounds\\ME\\and-he-will-be-powerful-alike-styling-and-not-to-tolerate-people-who-are-bad.wav, segment:1\n",
      "Sounds\\ME\\and-here-will-be-powerful-and-like-a-styling-and-the-note-to-tolerate-people-who-are-bad.wav, segment:1\n",
      "\n",
      "Processing: Sounds\\UK\n",
      "Sounds\\UK\\after-three-years-of-unfounded-self-doubt-it-is-time-to-change-the-record.wav, segment:1\n",
      "Sounds\\UK\\against-the-pluck-a-nerve-and-ambition-of-this-country.wav, segment:1\n",
      "Sounds\\UK\\all-this-and-more-we-can-do-now-and-only-now-at-this-extraordinary.wav, segment:1\n",
      "Sounds\\UK\\always-observed-a-top-speed-limit-in-the.wav, segment:1\n",
      "Sounds\\UK\\and-and-and-and-and.wav, segment:1\n",
      "Sounds\\UK\\and-around-the-eu-i-am-convinced-we-can-do-a-deal.wav, segment:1\n",
      "Sounds\\UK\\and-as-affectionate-as-possible-and-the-first-step-is.wav, segment:1\n",
      "Sounds\\UK\\and-even-loved-around-the-world-for-our-inventiveness-farrar-hume.wav, segment:1\n",
      "Sounds\\UK\\and-fantastic-new-road-and-rail-infrastructure-and-full-fibre-broadband.wav, segment:1\n",
      "Sounds\\UK\\and-farming-sector-will-be-ready-and-waiting-to-continue-selling.wav, segment:1\n",
      "\n",
      "Processing: Sounds\\US\n",
      "Sounds\\US\\a-woman-that-looks-like-that-has-to-have-special-scent.wav, segment:1\n",
      "Sounds\\US\\ah-im-smart.wav, segment:1\n",
      "Sounds\\US\\ah-no.wav, segment:1\n",
      "Sounds\\US\\america-great-again.wav, segment:1\n",
      "Sounds\\US\\america.wav, segment:1\n",
      "Sounds\\US\\and-i-made-a-lot-of-money-in-atlantic-city-and-im-very-proud-of-it.wav, segment:1\n",
      "Sounds\\US\\and-i-will-tell-you-this-and-i-said-it-very-strongly.wav, segment:1\n",
      "Sounds\\US\\and-it-only-makes-common-sense.wav, segment:1\n",
      "Sounds\\US\\and-now-theyre-beating-us-economically-they-are-not-our-friend-believe-maine.wav, segment:1\n",
      "Sounds\\US\\and-some-i-assume-are-good-people.wav, segment:1\n"
     ]
    }
   ],
   "source": [
    "save_mfcc(DATASET_PATH, JSON_PATH, num_segments=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_10.json\"\n",
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "\n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # build network topology\n",
    "    model = keras.Sequential([\n",
    "\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "\n",
    "        # 1st dense layer\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "        # 2nd dense layer\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # 3rd dense layer\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 61.1237 - accuracy: 0.1905\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 38.0066 - accuracy: 0.2857\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 24.8597 - accuracy: 0.2857\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.3332 - accuracy: 0.4762\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.2600 - accuracy: 0.5238\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0211 - accuracy: 0.7143\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8886 - accuracy: 0.7619\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7455 - accuracy: 0.8095\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1151 - accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0968 - accuracy: 0.7143\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2704 - accuracy: 0.8571\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9524\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3472e-06 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7815e-07 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6503e-08 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5413e-08 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2707e-08 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7030e-08 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3056e-07 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6169e-06 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2884e-05 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7136e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6264e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5714e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8412e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3581e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0313e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8590e-06 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4466e-06 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3056e-06 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3796e-07 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4278e-07 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7815e-07 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8733e-07 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3056e-07 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0826e-08 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8120e-08 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5413e-08 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4060e-08 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8383e-08 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2707e-08 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7030e-08 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1353e-08 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1353e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 3.4797 - accuracy: 0.8889\n",
      "test loss, test acc: 3.4797005653381348\n",
      "0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results, labels = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
